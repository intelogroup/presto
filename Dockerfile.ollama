# Ollama Service Dockerfile for Railway
# This runs Ollama with Llama 3.1 and Mistral models

FROM ollama/ollama:latest

# Set environment variables
ENV OLLAMA_HOST=0.0.0.0
ENV OLLAMA_PORT=11434

# Create ollama user and directories
RUN useradd -m -s /bin/bash ollama || true
RUN mkdir -p /home/ollama/.ollama
RUN chown -R ollama:ollama /home/ollama/.ollama

# Switch to ollama user
USER ollama
WORKDIR /home/ollama

# Copy startup script
COPY --chown=ollama:ollama scripts/start-ollama.sh /home/ollama/start-ollama.sh
RUN chmod +x /home/ollama/start-ollama.sh

# Expose the Ollama port
EXPOSE 11434

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:11434/api/tags || exit 1

# Start Ollama service
CMD ["/home/ollama/start-ollama.sh"]