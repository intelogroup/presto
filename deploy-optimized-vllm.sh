#!/bin/bash

# Deploy Optimized vLLM Llama 3.1 to Railway
# Performance-tuned configuration for maximum speed

set -e

echo "üöÄ Deploying Optimized vLLM Llama 3.1 to Railway"
echo "================================================"
echo ""

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Check if Railway CLI is installed
if ! command -v railway &> /dev/null; then
    echo -e "${RED}‚ùå Railway CLI not found. Please install it first:${NC}"
    echo "   npm install -g @railway/cli"
    echo "   or visit: https://docs.railway.app/develop/cli"
    exit 1
fi

# Check if user is logged in
if ! railway whoami &> /dev/null; then
    echo -e "${RED}‚ùå Not logged in to Railway. Please run:${NC}"
    echo "   railway login"
    exit 1
fi

echo -e "${GREEN}‚úÖ Railway CLI detected and authenticated${NC}"
echo ""

# Service configuration
SERVICE_NAME="llm-vllm-optimized"
CONFIG_FILE="railway-vllm-optimized.toml"

echo -e "${BLUE}üì¶ Creating optimized vLLM service: $SERVICE_NAME${NC}"

# Create new service for optimized LLM
echo "Creating Railway service..."
railway service create $SERVICE_NAME

# Switch to the LLM service
echo "Switching to $SERVICE_NAME service..."
railway service $SERVICE_NAME

# Copy optimized configuration
echo "Applying optimized configuration..."
cp $CONFIG_FILE railway.toml

echo ""
echo -e "${YELLOW}‚ö†Ô∏è  IMPORTANT: Set your Hugging Face token${NC}"
echo "   You need to set your Hugging Face Hub token for model access:"
echo -e "   ${BLUE}railway variables set HUGGING_FACE_HUB_TOKEN=your-token-here${NC}"
echo ""
echo "   Get your token from: https://huggingface.co/settings/tokens"
echo ""

# Ask user if they want to set the token now
read -p "Do you want to set your Hugging Face token now? (y/n): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    read -p "Enter your Hugging Face Hub token: " HF_TOKEN
    if [ ! -z "$HF_TOKEN" ]; then
        railway variables set HUGGING_FACE_HUB_TOKEN="$HF_TOKEN"
        echo -e "${GREEN}‚úÖ Hugging Face token set successfully${NC}"
    else
        echo -e "${YELLOW}‚ö†Ô∏è  Token not set. You can set it later with:${NC}"
        echo "   railway variables set HUGGING_FACE_HUB_TOKEN=your-token-here"
    fi
else
    echo -e "${YELLOW}‚ö†Ô∏è  Remember to set your token before deployment:${NC}"
    echo "   railway variables set HUGGING_FACE_HUB_TOKEN=your-token-here"
fi

echo ""
echo -e "${BLUE}üîß Setting optimized environment variables...${NC}"

# Set additional optimization variables
railway variables set VLLM_WORKER_USE_RAY="false"
railway variables set VLLM_ATTENTION_BACKEND="FLASHINFER"
railway variables set VLLM_GPU_MEMORY_UTILIZATION="0.95"
railway variables set VLLM_MAX_NUM_BATCHED_TOKENS="16384"
railway variables set VLLM_MAX_NUM_SEQS="512"
railway variables set VLLM_NUM_SCHEDULER_STEPS="12"
railway variables set VLLM_ENABLE_CHUNKED_PREFILL="false"
railway variables set VLLM_DISABLE_LOG_REQUESTS="true"

echo -e "${GREEN}‚úÖ Optimization variables configured${NC}"
echo ""

# Deploy the service
echo -e "${BLUE}üö¢ Deploying optimized vLLM service...${NC}"
railway up --detach

echo ""
echo -e "${GREEN}üéâ Deployment initiated successfully!${NC}"
echo ""
echo "üìä Performance Optimizations Applied:"
echo "   ‚Ä¢ GPU Memory Utilization: 95%"
echo "   ‚Ä¢ Max Batched Tokens: 16,384"
echo "   ‚Ä¢ Max Sequences: 512"
echo "   ‚Ä¢ Scheduler Steps: 12"
echo "   ‚Ä¢ Chunked Prefill: Disabled (for better latency)"
echo "   ‚Ä¢ FlashAttention: Enabled"
echo "   ‚Ä¢ Request Logging: Disabled (for performance)"
echo ""
echo "üîç Monitor your deployment:"
echo "   railway logs"
echo ""
echo "üåê Get service URL:"
echo "   railway domain"
echo ""
echo "üìà Expected Performance Improvements:"
echo "   ‚Ä¢ ~30-50% faster inference speed"
echo "   ‚Ä¢ Better GPU utilization"
echo "   ‚Ä¢ Reduced memory overhead"
echo "   ‚Ä¢ Optimized batch processing"
echo ""
echo -e "${YELLOW}‚è≥ Note: Initial deployment may take 10-15 minutes for model download${NC}"
echo -e "${GREEN}‚ú® Your optimized vLLM Llama 3.1 service is being deployed!${NC}"