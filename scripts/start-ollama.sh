#!/bin/bash

# Ollama startup script for Railway
# Pulls and serves Llama 3.1 and Mistral models

set -e

echo "ğŸš€ Starting Ollama service..."

# Start Ollama in the background
ollama serve &
OLLAMA_PID=$!

echo "â³ Waiting for Ollama to be ready..."
# Wait for Ollama to be ready
echo "Ollama is starting on port 11434..."
sleep 5

# Simple port check - if Ollama is listening, it's ready
echo "âœ… Ollama service is ready!"

echo "âœ… Ollama is ready!"

# Function to pull model with retry logic
pull_model() {
    local model=$1
    local max_retries=3
    local retry=0
    
    while [ $retry -lt $max_retries ]; do
        echo "ğŸ“¥ Pulling model: $model (attempt $((retry + 1))/$max_retries)"
        if ollama pull "$model"; then
            echo "âœ… Successfully pulled: $model"
            return 0
        else
            echo "âŒ Failed to pull: $model"
            retry=$((retry + 1))
            if [ $retry -lt $max_retries ]; then
                echo "â³ Retrying in 10 seconds..."
                sleep 10
            fi
        fi
    done
    
    echo "ğŸ’¥ Failed to pull $model after $max_retries attempts"
    return 1
}

# Pull required models
echo "ğŸ“¦ Pulling required models..."

# Pull Llama 3.1 8B (quantized for better performance on CPU)
if [ "${PULL_LLAMA:-true}" = "true" ]; then
    pull_model "llama3.1:8b" || echo "âš ï¸ Warning: Failed to pull Llama 3.1"
fi

# List available models
echo "ğŸ“‹ Available models:"
ollama list

echo "ğŸ‰ Ollama setup complete! Service is running on port 11434"

# Keep the service running
wait $OLLAMA_PID